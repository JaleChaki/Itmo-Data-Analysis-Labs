{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6871c8de",
   "metadata": {},
   "source": [
    "### Топ-100 самых частовстречаемых слов в книге \"Война и Мир\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba74cde2",
   "metadata": {},
   "source": [
    "Откроем файл и прочитаем весь текст книги"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8e2d088",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Lev Tolstoy - Voyna i mir.txt') as f:\n",
    "    dirty_text = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b56a1d",
   "metadata": {},
   "source": [
    "Разобьём его на предложения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9b40581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15283\n"
     ]
    }
   ],
   "source": [
    "from rusenttokenize import ru_sent_tokenize\n",
    "\n",
    "dirty_sentences = ru_sent_tokenize(dirty_text)\n",
    "print(len(dirty_sentences))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7713c3",
   "metadata": {},
   "source": [
    "Очистим от знаков препинания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42d3aa9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def clear(s):\n",
    "    for ch in string.punctuation:\n",
    "        s = s.replace(ch,'')\n",
    "    return s.lower()\n",
    "\n",
    "clean_sentences = [clear(sentence) for sentence in dirty_sentences]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de88e94e",
   "metadata": {},
   "source": [
    "Сформируем список стоп-слов. Т.к. в книге часто встречаются французский, то надо учесть и русские, и французские слова."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b26d564",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "sw = stopwords.words('russian') + stopwords.words('french') + ['a', '–'] # русские, французские и выпавшие из обоих списков \n",
    "                                                                         # объекты"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816eb734",
   "metadata": {},
   "source": [
    "Выкинем стоп слова, остальные нормализуем. Нормализация выполняется только для русского языка, т.к. несмотря на то, что во французском языке тоже есть падежи, они формируются при помощи предлогов, а т.к. они находятся среди стоп-слов то нормализация им не нужна."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e67799a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pymorphy2\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "def approved_by_morph(word, morph):\n",
    "    p = morph.parse(word)\n",
    "    # отбойник на случай, если морфологический анализ не смог выдать результата\n",
    "    if(p == None) or (len(p) == 0):\n",
    "        return True\n",
    "    \n",
    "    if('NOUN' in p[0].tag) or ('LATN' in p[0].tag):   # отбираем либо существительные, либо то, \n",
    "                                                      # что морфологический анализ посчитал иностранным словом\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "        \n",
    "def normalize(word, morph):\n",
    "    p = morph.parse(word)\n",
    "    if(p == None) or (len(p) == 0):\n",
    "        return word\n",
    "    return p[0].normal_form\n",
    "\n",
    "def post_clear(words, forbidden_words, morph):\n",
    "    return [normalize(word, morph) for word in words if word not in forbidden_words and approved_by_morph(word, morph)]\n",
    "\n",
    "prepared_text = [post_clear(s.split(), sw, morph) for s in clean_sentences]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6277b7",
   "metadata": {},
   "source": [
    "Сформируем граф, отсортируем слова по степени связности с другими"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2996f118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7847\n",
      "273766\n"
     ]
    }
   ],
   "source": [
    "graph = {}\n",
    "\n",
    "for sentence in prepared_text:\n",
    "    for word in sentence:\n",
    "        graph[word] = {}\n",
    "\n",
    "for sentence in prepared_text:\n",
    "    for word1 in sentence:\n",
    "        for word2 in sentence:\n",
    "            #if (word1 < word2):\n",
    "                #word1, word2 = word2, word1 # swap values\n",
    "            if (word1 == word2):\n",
    "                continue\n",
    "            if word2 in graph[word1]:\n",
    "                graph[word1][word2] += 1\n",
    "            else:\n",
    "                graph[word1][word2] = 1\n",
    "                \n",
    "            if word1 in graph[word2]:\n",
    "                graph[word2][word1] += 1\n",
    "            else:\n",
    "                graph[word2][word1] = 1\n",
    "\n",
    "vertices_count = len(graph)\n",
    "edge_count = 0\n",
    "top = {}\n",
    "for edge in graph:\n",
    "    top[edge] = 0\n",
    "    for word2 in graph[edge]:\n",
    "        graph[edge][word2] /= 2\n",
    "        edge_count += 1\n",
    "        top[edge] += 1\n",
    "\n",
    "top = dict(sorted(top.items(), key = lambda item: -item[1]))\n",
    "        \n",
    "print(vertices_count)\n",
    "print(edge_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539015f4",
   "metadata": {},
   "source": [
    "Посмотрим на наш \"топ\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f012ca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['князь', 'человек', 'пьер', 'андрей', 'лицо', 'рука', 'время', 'дело', 'глаз', 'ростов', 'граф', 'слово', 'наташа', 'княжна', 'голос', 'день', 'анна', 'дом', 'друг', 'минута', 'голова', 'марья', 'улыбка', 'офицер', 'государь', 'место', 'борис', 'сторона', 'николай', 'жизнь', 'отец', 'комната', 'год', 'лошадь', 'солдат', 'нога', 'разговор', 'сила', 'сын', 'вид', 'графиня', 'чувство', 'император', 'c’est', 'денисов', 'генерал', 'павлович', 'кутузов', 'plus', 'свет', 'москва', 'армия', 'княгиня', 'выражение', 'дверь', 'стол', 'письмо', 'шаг', 'мысль', 'comme', 'вечер', 'войско', 'звук', 'василий', 'жена', 'бог', 'француз', 'соня', 'часть', 'любовь', 'наполеон', 'душа', 'гость', 'дорога', 'общество', 'брат', 'петербург', 'анатоль', 'обед', 'безухов', 'женщина', 'мать', 'михаилович', 'тысяча', 'si', 'движение', 'бонапарт', 'сражение', 'адъютант', 'гора', 'счастие', 'положение', 'взгляд', 'багратион', 'война', 'изз', 'платье', 'деревня', 'командир', 'час']\n"
     ]
    }
   ],
   "source": [
    "top100 = []\n",
    "keys = list(top.keys())\n",
    "for i in range(0, 100):\n",
    "    top100.append(keys[i])\n",
    "    \n",
    "print(top100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87c9adb",
   "metadata": {},
   "source": [
    "Всё готово к экспорту в граф"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0880a110",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('graph_nodes.csv', 'w') as f:\n",
    "    f.write('Id;Label\\n')\n",
    "    for word in top100:\n",
    "        f.write(word + ';' + word + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1cebf5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('graph_edges.csv', 'w') as f:\n",
    "    f.write('Source;Target;Weight\\n')\n",
    "    for word in top100:\n",
    "        for edge in graph[word]:\n",
    "            # граф получается слишком плотным, поэтому выкидываем все рёбра весом меньше 10\n",
    "            if (edge not in top100) or (graph[word][edge] <= 10.0):\n",
    "                continue\n",
    "            f.write(word + ';' + edge + ';' + str(graph[word][edge]) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ba9b2d",
   "metadata": {},
   "source": [
    "Импортируем файлы в Gephi, настраиваем отображение, смотрим на результат"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f22100",
   "metadata": {},
   "source": [
    "![](graph2.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
